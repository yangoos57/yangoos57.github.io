---
publish: false
title: "ğŸ¤— Transformersë¥¼ í™œìš©í•´ Torchserve ë°°í¬í•˜ê¸°"
category: ["ML ops","pytorch","torch serve"]
date: "2023-01-18"
thumbnail: "/assets/blog/mlops/torchserve/thumbnail.png"
ogImage:
  url: "/assets/blog/mlops/torchserve/thumbnail.png"
desc: "ì´ ê¸€ì€ ğŸ¤— Transformersë¡œ ëª¨ë¸ì„ Fine-tuningí•œ ë’¤ Torchserveë¡œ ë°°í¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ê¸€ì€ yelp ë°ì´í„° ì…‹ì„ í™œìš©í•´ Distil-bertë¥¼ Text Classification ëª¨ë¸ë¡œ Fine-tuningí•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. ëª¨ë¸ Fine-tuningì€ Huggingfae Fine-tuning turorial ì˜ˆì œë¥¼ í™œìš©í–ˆìŠµë‹ˆë‹¤. ì´ ê¸€ì™¸ì—ë„ ì¶”ê°€ì ì¸ ì´í•´ê°€ í•„ìš”í•˜ë‹¤ë©´ í•´ë‹¹ íŠœí† ë¦¬ì–¼ë„ ì½ì–´ë³´ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. ì´ ê¸€ì€ yelp ë°ì´í„° ì…‹ì„ í™œìš©í•´ Distil-bertë¥¼ Text Classification ëª¨ë¸ë¡œ Fine-tuningí•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤. TorchServeëŠ” Serving Huggingface Transformers using TorchServeì˜ ì˜ˆì œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ 
ì˜ˆì œì—ëŠ” SequenceClassification ì™¸ì—ë„ token_classification, question_answering, text_generationì— ëŒ€í•œ ì˜ˆì œë„ í¬í•¨í•˜ê³  ìˆìœ¼ë‹ˆ í•„ìš”í•œ ê²½ìš° ì°¸ê³ ë°”ëë‹ˆë‹¤. "
---

### ë“¤ì–´ê°€ë©°

ì´ ê¸€ì€ ğŸ¤— Transformersë¡œ ëª¨ë¸ì„ Fine-tuningí•œ ë’¤ Torchserveë¡œ ë°°í¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì†Œê°œí•©ë‹ˆë‹¤.

ëª¨ë¸ Fine-tuningì€ [Huggingface í˜ì´ì§€ Fine-tuning turorial](https://huggingface.co/docs/transformers/training) ì˜ˆì œë¥¼ í™œìš©í–ˆìŠµë‹ˆë‹¤. ì´ ê¸€ì—ì„œ í™œìš©í•  ëª¨ë¸ì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•˜ë‹¤ë©´ í•´ë‹¹ ë§í¬ë¥¼ ì½ì–´ë³´ëŠ” ê²ƒì„ ì¶”ì²œí•©ë‹ˆë‹¤. TorchServeì— ëŒ€í•œ ì˜ˆì œëŠ” [Serving Huggingface Transformers using TorchServe](https://github.com/pytorch/serve/tree/master/examples/Huggingface_Transformers)ë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ì˜ˆì œì—ëŠ” SequenceClassification ì™¸ì—ë„ token_classification, question_answering, text_generationì— ëŒ€í•œ ì˜ˆì œë„ í¬í•¨í•˜ê³  ìˆìœ¼ë‹ˆ í•„ìš”ì‹œ ì°¸ê³  ë°”ëë‹ˆë‹¤.

### í•™ìŠµ & í‰ê°€ ë°ì´í„° ë§Œë“¤ê¸°

ë¨¼ì € Fine-tuningì— í•„ìš”í•œ í•™ìŠµ, í‰ê°€ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤. ì´ë•Œ huggingfaceì—ì„œ ì œê³µí•˜ëŠ” `datasets` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤. `datasets`ì˜ load_datsetì„ í™œìš©í•˜ë©´ [Huggingfaceì— ì—…ë¡œë“œ ëœ Datasets](https://huggingface.co/datasets)ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì˜ˆì œì—ì„œ í™œìš©í•  `yelp_review` ë°ì´í„°ì…‹ì˜ FeatureëŠ” labelê³¼ textì´ ìˆìŠµë‹ˆë‹¤. labelì€ ë ˆìŠ¤í† ë‘ì— ëŒ€í•œ í‰ì ì„ ì˜ë¯¸í•˜ê³  1~5 ë²”ìœ„ë¥¼ ê°–ìŠµë‹ˆë‹¤. textëŠ” í‰ì ê³¼ í•¨ê»˜ ì‘ì„±í•œ ë¦¬ë·°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤. yelpëŠ” í•œêµ­ì˜ ë‹¤ì´ë‹ì½”ë“œì™€ ìœ ì‚¬í•œ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ê¸°ì—…ì…ë‹ˆë‹¤. ë¯¸êµ­ ë‚´ ì¡´ì¬í•˜ëŠ” ë ˆìŠ¤í† ë‘ì˜ ë©”ë‰´, ìš´ì˜ì‹œê°„, ë ˆìŠ¤í† ë‘ í‰ê°€ ë“± ê°ì¢… ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì‚¬ì´íŠ¸ë¥¼ ìš´ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.

```python
{

'label' : 4,
'text' : '"dr. goldberg offers everything i look for in a general practitioner.
            he's nice and easy to talk to without being patronizing; he's always on
            time in seeing his patients; he's affiliated with a top-notch hospital (nyu)
            which my parents have explained to me is very important in case something happens
            and you need surgery; and you can get referrals to see specialists without
            having to see him first.  really, what more do you need?
            i'm sitting here trying to think of any complaints i have about him,
            but i'm really drawing a blank."'
}
```

<br/>
<br/>

load_dataset ë§¤ì„œë“œë¥¼ í™œìš©í•´ `yelp_review` ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤. ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ëŠ” DatasetDict íƒ€ì…ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤. DatasetDict ë‚´ë¶€ì—ëŠ” Dataset íƒ€ì…ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. DatasetDict ì‚¬ìš©ë²•ì€ ì¼ë°˜ Dictì™€ ë™ì¼í•©ë‹ˆë‹¤.

```python

from datasets import load_dataset

dataset = load_dataset("yelp_review_full")

dataset

>>> DatasetDict({
    train: Dataset({
        features: ['label', 'text'],
        num_rows: 650000
    })
    test: Dataset({
        features: ['label', 'text'],
        num_rows: 50000
    })
})

```

<br/>
<br/>

DatasetDict ë‚´ë¶€ì— train Datasetì„ ì„ íƒí•´ ë‚´ë¶€ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

```python

dataset['train'][:3]


>>> {
    'label': [4, 1, 3],
    'text': [
        "dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.",
        "Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.",
        "Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life."
        ]
    }
```

<br/>
<br/>

65,000ê°œì˜ í•™ìŠµ ë°ì´í„° ì¤‘ 1,000ê°œì˜ ë°ì´í„°ë¥¼ ì„ì˜ë¡œ ì¶”ì¶œí•˜ê³  í‰ê°€ìš© ë°ì´í„°ëŠ” 100ê°œë¥¼ ì¶”ì¶œí•˜ê² ìŠµë‹ˆë‹¤.

```python
# train
train_dataset = train_dataset = dataset["train"].shuffle(seed=42).select(range(1000))

# validation
validation_dataset = dataset["test"].shuffle(seed=42).select(range(100))
```

<br/>
<br/>

ë°ì´í„° ì¶”ì¶œ ê³¼ì •ì„ ë°˜ë³µí•˜ì§€ ì•Šê¸° ìœ„í•´ csv íŒŒì¼ë¡œ ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤. csvë¡œ ì €ì¥í•˜ê¸° ìœ„í•´ `.to_csv`ë¥¼ ë§¤ì„œë“œë¥¼ í™œìš©í•©ë‹ˆë‹¤. dataset ë‚´ë¶€ëŠ” pandasë¥¼ í™œìš©í•˜ë¯€ë¡œ pandasì˜ `.to_csv` ë§¤ì„œë“œë¥¼ ì‚¬ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
train_dataset.to_csv('data/train.csv',index=False)
validation_dataset.to_csv('data/validation.csv',index=False)

# index=False : csvì— í¬í•¨ëœ indexë¥¼ ì €ì¥í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥
```

<br/>
<br/>

ì €ì¥í•œ csv íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

```python
# load_dataset
data = load_dataset("csv",data_files={'train':'data/train.csv','validation':'data/test.csv'})

data

>>>DatasetDict({
   train: Dataset({
       features: ['label', 'text'],
       num_rows: 1000
  })
  validation: Dataset({
      features: ['label', 'text'],
      num_rows: 50
  })
})
```

<br/>
<br/>
<br/>

### ğŸ¤— Transformersì˜ ëª¨ë¸ êµ¬ì¡° ì´í•´í•˜ê¸°(ê°œë…)

í•™ìŠµ & í‰ê°€ì— ì‚¬ìš© ë  ë°ì´í„°ë¥¼ ì €ì¥í–ˆìœ¼ë‹ˆ ğŸ¤— Transformersë¥¼ í™œìš©í•´ ëª¨ë¸ì„ Fine-tuningí•˜ëŠ” ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤. ë¨¼ì € ğŸ¤— Transformersì˜ ê¸°ë³¸ ê°œë…ì— ëŒ€í•´ì„œ ê°„ëµí•˜ê²Œ ì†Œê°œí•˜ê² ìŠµë‹ˆë‹¤.

ğŸ¤— Transformersì˜ ì¥ì ì€ ìˆ˜í–‰í•´ì•¼ í•˜ëŠ” Taskì— ì í•©í•œ êµ¬ì¡°ë¥¼ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆëŠ” ê²ƒì— ìˆìŠµë‹ˆë‹¤. ğŸ¤— Transformersì—ì„œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆëŠ” êµ¬ì¡°ëŠ” ì•ìœ¼ë¡œ ì˜ˆì œì—ì„œ í™œìš©í•  Distil-Bertì˜ ê²½ìš° `MaskedLM`, `SequenceClassification`, `MultipleChoice`, `TokenClassification`, `QuestionAnswering` ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ êµ¬ì¡°ë“¤ì€ `BaseModel`ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜ ì¶œë ¥ ìƒë‹¨(output-Layer) êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸°ì¡´ì— ë§Œë“¤ì–´ì§„ Layerë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì§ì ‘ Layerë¥¼ êµ¬ì„±í•´ì•¼í•œë‹¤ë©´ BaseModelì„ ì§ì ‘ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img src='/assets/blog/mlops/torchserve/img2.png' alt='img2'>

<br/>
<br/>

ì´ë ‡ê²Œ ì¶œë ¥ ìƒë‹¨ êµ¬ì¡°ê°€ ë‹¤ì–‘í•œ ì´ìœ ëŠ” Task ë³„ë¡œ í•„ìš”í•œ Output í˜•íƒœê°€ ë‹¤ë¥´ê¸° ë–„ë¬¸ì…ë‹ˆë‹¤. ì˜ˆë¡œë“¤ì–´ MaskedLM êµ¬ì¡°ì˜ ê²½ìš° input dataì— ì¡´ì¬í•˜ëŠ” [MASK]ì— ë“¤ì–´ê°ˆ ë‹¨ì–´ë“¤ì˜ ìˆœìœ„ë¥¼ Outputìœ¼ë¡œ ì¶œë ¥í•´ì•¼í•©ë‹ˆë‹¤. ë°˜ë©´ Sequence Classificationì€ ë¬¸ì¥ ìœ í˜•ì„ ë¶„ë¥˜í•˜ê±°ë‚˜ í™•ë¥ ì„ ì˜ˆì¸¡í•´ì•¼í•˜ëŠ” êµ¬ì¡°ì—ì„œ í™œìš©í•´ì•¼ í•˜ë¯€ë¡œ 0~1 ë²”ìœ„ì˜ ê°’(Regression ëª¨ë¸), ë˜ëŠ” ì •ìˆ˜ê°’(Classification ëª¨ë¸)ì˜ Outuputì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ğŸ¤— Transformerì˜ ê¸°ë³¸ êµ¬ì¡°ì— ëŒ€í•´ ì–´ëŠì •ë„ íŒŒì•…í–ˆìœ¼ë‹ˆ ìš°ë¦¬ê°€ ë§Œë“¤ì–´ì•¼ í•˜ëŠ” ëª¨ë¸ì´ ì–´ë– í•œ êµ¬ì¡°ë¥¼ ê°€ì ¸ì•¼ í•˜ëŠ”ì§€ë¡œ ì£¼ì œë¥¼ ì¢í˜€ë³´ê² ìŠµë‹ˆë‹¤. ìš°ë¦¬ê°€ ë§Œë“¤ê³ ì í•˜ëŠ” ëª¨ë¸ì€ ë ˆìŠ¤í† ë‘ ë¦¬ë·° ë°ì´í„°ë¥¼ Input ë°ì´í„°ë¡œ í™œìš©í•´ í‰ì ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ëª¨ë¸ì´ ë°˜í™˜í•´ì•¼ í•˜ëŠ” Outputì€ í‰ì ì„ ì˜ë¯¸í•˜ëŠ” 1~5ì˜ ê°’ ì¤‘ í•˜ë‚˜ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìœ í˜•ì˜ ëª¨ë¸ì„ classification ëª¨ë¸ì´ë¼ í•˜ë©° ğŸ¤— Transformersì˜ SequenceClassification êµ¬ì¡°ë¥¼ ë¶ˆëŸ¬ì™€ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

SequenceClassification êµ¬ì¡°ëŠ” ë‹¤ì–‘í•œ ìœ í˜•ì˜ ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ì´ë¯€ë¡œ ì´ì— ëŒ€í•´ì„œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³  ë„˜ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. SequenceClassificationì€ ìš°ë¦¬ê°€ êµ¬í˜„í•˜ê³ ì í•˜ëŠ” ê¸°ëŠ¥ (1~5 ì‚¬ì´ì˜ outputì„ ë°˜í™˜í•˜ëŠ” Classification ëª¨ë¸)ì™¸ì—ë„ ë‹¤ì–‘í•œ taskì— ì ìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. input data êµ¬ì¡°ì™€ SequenceClassificationì˜ ì¸ìì¸ num_label ê°’ì„ ì–´ë–»ê²Œ ì„¤ì •í•˜ëŠëƒì— ë”°ë¼ Taskì— í•„ìš”í•œ êµ¬ì¡°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ë¨¼ì € input data êµ¬ì¡°ëŠ” ë¬¸ì¥ì„ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°ì™€ ë¬¸ì¥ ë‘ ê°œë¥¼ í•˜ë‚˜ë¡œ ì—°ê²°í•´ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°ë¡œ ë‚˜ëˆ ì§‘ë‹ˆë‹¤. Text classification ìœ í˜•ì€ ë¬¸ì¥ í•˜ë‚˜ë¥¼ input dataë¡œ í™œìš©í•˜ëŠ” ê²½ìš°ì— í•´ë‹¹í•˜ë©° Sentence Similarity, Q&A, Inference ìœ í˜•ì€ ë¬¸ì¥ ë‘ ê°œë¥¼ ì—°ê²°í•´ input dataë¡œ í™œìš©í•˜ëŠ” ê²½ìš°ì— í•´ë‹¹í•©ë‹ˆë‹¤. ì´ë•Œ ë‘ ê°œì˜ ë¬¸ì¥ì„ êµ¬ë¶„í•˜ëŠ” ë°©ë²•ìœ¼ë¡œëŠ” data êµ¬ì¡°ì•ˆì— [SEP] í† í°ì„ í†µí•´ êµ¬ë¶„í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ë‘ ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ëœ ë°ì´í„°ëŠ” ëª¨ë¸ ë‚´ë¶€ì—ì„œ [SEP]ì„ ê¸°ì¤€ìœ¼ë¡œ Cross-Atteionì„ í†µí•´ ê´€ê³„ë¥¼ íŒŒì•…í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë•Œ ë¬¸ì¥ ê°„ ê´€ê³„ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ” ê°’ì€ [CLS] í† í°ì— ì €ì¥ë˜ë¯€ë¡œ [CLS] embeddingì´ SequenceClassificationì˜ Input dataë¡œ í™œìš©ë©ë‹ˆë‹¤.

ë‹¤ìŒìœ¼ë¡œ num_labelì€ output ìœ í˜•ì„ ê²°ì •í•©ë‹ˆë‹¤. num_label = 1ë¡œ ì„¤ì •í•˜ë©´ ëª¨ë¸ì€ 0~1ì‚¬ì´ ë²”ìœ„ì˜ Outputì„ ì œê³µí•©ë‹ˆë‹¤. num_labelì„ 2 ì´ìƒìœ¼ë¡œ ì„¤ì •í•˜ë©´ Softmaxë¥¼ í™œìš©í•´ Labelì˜ ì´í•©ì´ 1ì´ ë˜ë„ë¡ Outputì„ ì œê³µí•©ë‹ˆë‹¤. yelp_review ë°ì´í„°ì…‹ì„ ì˜ˆë¡œë“¤ë©´ labelì´ 5ê°œì´ë¯€ë¡œ Outputì€ `1 : 0.2, 2: 0.01, 3 : 0.5, 4: 0.19, 5: 0.1` ê³¼ ê°™ì´ ì œê³µë˜ë©° í™•ë¥ ê°’ì„ í†µí•´ Input Dataì— ëŒ€í•œ ì˜ˆì¸¡ê°’ì´ 3ì´ë¼ íŒë‹¨í•˜ê²Œ ë©ë‹ˆë‹¤.

<img src='/assets/blog/mlops/torchserve/img1.png' alt='img1'>

<br/>
<br/>

### Sequenceclassification Model í•™ìŠµí•˜ê¸°(ì ìš©)

SequenceClassification êµ¬ì¡°ë¥¼ ì´í•´í–ˆìœ¼ë‹ˆ ì´ì œ BaseModelì„ Text classification ëª¨ë¸ë¡œ Fine-tuning í•˜ê² ìŠµë‹ˆë‹¤.

ëª¨ë¸ì´ ì˜ˆì¸¡í•´ì•¼í•˜ëŠ” outputì€ 5ê°œ(í‰ì  1~5ì )ì´ë¯€ë¡œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ í•„ìš”í•œ num_labelì„ 5ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.

> Tokenizing, TrainingArguments, Trainer, Callbackì— ëŒ€í•œ ì„¤ëª…ì€ [ELECTRA í•™ìŠµ êµ¬ì¡° ì†Œê°œ ë° Domain Adaptation ìˆ˜í–‰í•˜ê¸°](https://yangoos57.github.io/blog/DeepLearning/paper/Electra/electra/)ì—ì„œ ë‹¤ë£¨ê³  ìˆìœ¼ë‹ˆ ìƒëµí•˜ê² ìŠµë‹ˆë‹¤.

```python

from transformers import (
        DistilBertForSequenceClassification,
        DistilBertTokenizer,
        Trainer,
        TrainingArguments,
        TrainerCallback
    )
import pandas as pd

# load_dataset
data = load_dataset("csv",data_files={'train':'data/train.csv','validation':'data/test.csv'})

train_dataset = data['train']
evaluation_dataset = data['validation']

print('Complete Loading')


# Tokenizing
tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")

def tokenize_function(item):
    return tokenizer(item["text"], padding="max_length", max_length=128, truncation=True)

train = train_dataset.map(tokenize_function)
evaluation = evaluation_dataset.map(tokenize_function)

print('Complete Tokenizing')



tra_args= TrainingArguments(
num_train_epochs=1,
output_dir="test",
logging_steps=10,
# evaluation_strategy="epoch",
)

class myCallback(TrainerCallback):

    def on_log(self, args, state, control, logs=None, **kwargs):
        print(f'{state.global_step}íšŒ ì§„í–‰ ì¤‘ ')

# num_label = 5
model = DistilBertForSequenceClassification.from_pretrained(
"distilbert-base-uncased", num_labels=5
)

trainer = Trainer(
model=model,
args=tra_args,
train_dataset=train,
eval_dataset=evaluation,
callbacks=[myCallback]
)

trainer.train()

```

<br/>
<br/>
<br/>

### torchserve ìƒì„±í•˜ê¸°

í•™ìŠµì´ ì™„ë£Œëë‹¤ë©´ í•™ìŠµí•œ ëª¨ë¸ì„ ì„œë¹™í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ğŸ¤— Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë‚´ë¶€ëŠ” pytorchë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ëê¸° ë•Œë¬¸ì— ğŸ¤— Transformersë¡œ í•™ìŠµí•œ ëª¨ë¸ì€ torchserveë¡œ ë°°í¬í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ëª¨ë¸ì„ torchserveë¡œ ë°°í¬í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

> ëª¨ë¸, í† í¬ë‚˜ì´ì € ì €ì¥, í•¸ë“¤ëŸ¬(Handler) ì œì‘ â¡ï¸ MAR file ìƒì„± â¡ï¸ torchserveë¡œ ë°°í¬

MAR fileì€ `torch-model-archiver`ë¥¼ í†µí•´ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„  Handlerì™€ model, tokenzierê°€ í•„ìš”í•©ë‹ˆë‹¤. Handler ì„¤ëª…ì— ì•ì„œ trainerë¥¼ í†µí•´ í•™ìŠµí•œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ `torch_model` í´ë”ì— ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤. ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ëª¨ë‘ ê°™ì€ ê²½ë¡œì— ì €ì¥í•´ì£¼ì„¸ìš”.

```python
trainer.save_model('torch_model')
tokenizer.save_pretrained('torch_model')
```

ì €ì¥ ê²°ê³¼ë¡œ `handler.py`ë¥¼ ì œì™¸í•œ 6ê°œì˜ íŒŒì¼ì´ ìƒì„±ëœê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img src='/assets/blog/mlops/torchserve/img3.png' alt='img3'>

### Handlerê°€ í•„ìš”í•œ ì´ìœ 

Product í™˜ê²½ì—ì„œëŠ” í•™ìŠµìš© ë°ì´í„°ì™€ ê°™ì´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë¥¼ ì œê³µ ë°›ì„ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡(Predict)ì— ì•ì„œ ë°ì´í„° ì „ì²˜ë¦¬ê°€ í•„íˆ ìˆ˜í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆì¸¡ì„ í†µí•´ ì–»ì€ ê²°ê³¼ì— ëŒ€í•œ í›„ì²˜ë¦¬ë„ í•„ìš”í•©ë‹ˆë‹¤. ëª¨ë¸ outputì„ ë°˜í™˜í•  ë•Œ íŠ¹ì • ì–‘ì‹ì— ë§ì¶°ì„œ ë°˜í™˜í•˜ê±°ë‚˜ Metricì„ ìƒì„±í•´ì•¼í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ë°ì´í„° ì „ì²˜ë¦¬ - ì¶”ë¡  - í›„ì²˜ë¦¬ì˜ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ëŠ”ë° í•„ìš”í•œ ê¸°ëŠ¥ì„ torchserveì—ì„œëŠ” Handlerë¼ ë¶€ë¦…ë‹ˆë‹¤.

### ğŸ¤— Transformersë¥¼ ìœ„í•œ Handler

HandlerëŠ” BaseHandler Classë¥¼ ìƒì†ë°›ì•„ ì‘ì„±í•©ë‹ˆë‹¤. nn.Moduleì„ ì‚¬ìš©í•´ ëª¨ë¸ì„ ì œì‘í•  ë•Œ forwardë¥¼ ì¬ì‘ì„±í•˜ëŠ” ê²ƒì²˜ëŸ¼, Handler ë˜í•œ BaseHandlerë¥¼ ë¶ˆëŸ¬ì˜¨ ë’¤ preprocess, postprocessë¥¼ êµ¬ì„±í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì œì‘í•©ë‹ˆë‹¤.

ğŸ¤— Transformersë¥¼ ì‚¬ìš©í–ˆì„ ê²½ìš° transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì™€ì•¼ í•˜ë¯€ë¡œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ì¸ initialize í•¨ìˆ˜ë„ ì¼ë¶€ ìˆ˜ì •í•´ì•¼í•©ë‹ˆë‹¤. ì´ë•Œ ë³€ê²½í•  ì‚¬í•­ì€ ë‘ ê°€ì§€ì…ë‹ˆë‹¤. í•˜ë‚˜ëŠ” `self.model`, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” `self.tokenizer`ì…ë‹ˆë‹¤. ì´ ì™¸ì—ëŠ” BaseHandlerì˜ êµ¬ì¡°ì™€ ë™ì¼í•©ë‹ˆë‹¤.

ì•„ë˜ ì œê³µí•œ HandlersëŠ” ê¸°ë³¸ êµ¬ì¡°ì´ë¯€ë¡œ preprocessì™€ postprocessì˜ ë‚´ìš©ì„ ì…ë§›ì— ë§ê²Œ ë³€ê²½í•˜ì‹œë©´ ë©ë‹ˆë‹¤. Handler Class ì„¤ì • ë‹¤ìŒì— ë‚˜ì˜¤ëŠ” Handle í•¨ìˆ˜ëŠ” Handlerë¥¼ ì‘ë™ì‹œí‚¤ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. ìŠì§€ë§ê³  í¬í•¨í•´ì£¼ì„¸ìš”.

ì»¤ìŠ¤í„°ë§ˆì´ì§• ì´í›„ handler.pyë¥¼ `torch_model` í´ë”ì— í•¨ê»˜ ì €ì¥í•´ì£¼ì„¸ìš”.

```python
from abc import ABC
import json
import logging
import os

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

from ts.torch_handler.base_handler import BaseHandler

logger = logging.getLogger(__name__)


class TransformersClassifierHandler(BaseHandler, ABC):
    def __init__(self):
        super(TransformersClassifierHandler, self).__init__()
        self.initialized = False

    def initialize(self, ctx):
        self.manifest = ctx.manifest

        properties = ctx.system_properties
        model_dir = properties.get("model_dir")
        self.device = torch.device(
            "cuda:" + str(properties.get("gpu_id")) if torch.cuda.is_available() else "cpu"
        )

        # Read model serialize/pt file
        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)

        self.model.to(self.device)
        self.model.eval()

        logger.debug("Transformer model from path {0} loaded successfully".format(model_dir))

        # Read the mapping file, index to object name
        mapping_file_path = os.path.join(model_dir, "index_to_name.json")

        if os.path.isfile(mapping_file_path):
            with open(mapping_file_path) as f:
                self.mapping = json.load(f)
        else:
            logger.warning(
                "Missing the index_to_name.json file. Inference output will not include class name."
            )

        self.initialized = True

    def preprocess(self, data):
        """Very basic preprocessing code - only tokenizes.
        Extend with your own preprocessing steps as needed.
        """
        print("------- input data í™•ì¸ --------")
        print(data)
        text = data[0].get("data")
        if text is None:
            text = data[0].get("body")

        logger.info("Received text: '%s'", text)

        inputs = self.tokenizer.encode_plus(text, add_special_tokens=True, return_tensors="pt")
        return inputs

    def inference(self, inputs):
        """
        Predict the class of a text using a trained transformer model.
        """
        # NOTE: This makes the assumption that your model expects text to be tokenized
        # with "input_ids" and "token_type_ids" - which is true for some popular transformer models, e.g. bert.
        # If your transformer model expects different tokenization, adapt this code to suit
        # its expected input format.
        inputs = inputs.to(self.device)

        prediction = self.model(**inputs)[0].argmax().item()
        logger.info("Model predicted: '%s'", prediction)

        if self.mapping:
            prediction = self.mapping[str(prediction)]
        return [prediction]

    def postprocess(self, inference_output):
        # TODO: Add any needed post-processing of the model predictions here
        logger.info("Model Name: '%s'", self.model.config._name_or_path)
        logger.info("Model predicted: '%s'", inference_output)
        return inference_output


_service = TransformersClassifierHandler()


def handle(data, context):
    try:
        if not _service.initialized:
            _service.initialize(context)

        if data is None:
            return None

        data = _service.preprocess(data)
        data = _service.inference(data)
        data = _service.postprocess(data)

        return data
    except Exception as e:
        raise e

```

### MAR file ìƒì„±í•˜ê¸°

ì´ì œ Mar fileì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¡°ê±´ì´ ê°–ì¶°ì¡ŒìŠµë‹ˆë‹¤. model, tokenizer, handlerê°€ ë™ì¼í•œ ê²½ë¡œì— ìˆëŠ”ì§€ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”.

MAR file ìƒì„±ì€ ì»¤ë§¨ë“œì—ì„œ `torch-model-archiver`ë¥¼ ì‹¤í–‰í•´ ìƒì„±í•©ë‹ˆë‹¤.

> torch-model-archiver í™œìš©ì„ ìœ„í•´ `pip install torchserve torch-model-archiver torch-workflow-archiver`ì„ ìš°ì„  ì„¤ì¹˜í•´ì£¼ì„¸ìš”

Terminalì„ ì¼œì„œ model, tokenizer, handlerê°€ ìˆëŠ” ê²½ë¡œë¡œ ì´ë™í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ë³¸ì¸ì´ ì €ì¥í•œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”. `--serialized-file pytorch_model.bin`, `--handler "handler.py"`, `--extra-files "config.json,vocab.txt"` ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

```bash
torch-model-archiver --model-name bert-model --version 1.0 --serialized-file pytorch_model.bin  --handler "handler.py" --extra-files "config.json,vocab.txt"
```

commandë¥¼ ì‹¤í–‰í•˜ë©´ `torch_model` í´ë”ì— bert-model.mar íŒŒì¼ì´ ìƒˆë¡œ ìƒê¸´ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

MAR Fileì˜ ë‚´ë¶€êµ¬ì¡°ëŠ” argsì— í¬í•¨í•œ íŒŒì¼ + MAR_INF í´ë” ë‚´ë¶€ì— ìˆëŠ” json íŒŒì¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

<img src='/assets/blog/mlops/torchserve/img4.png' alt='img4'>

```json
# MAR_INF ë‚´ë¶€ Json ì •ë³´
{
    "createdOn": "17/01/2023 18:36:16",
  "runtime": "python",
  "model": {
      "modelName": "bert-model",
    "serializedFile": "pytorch_model.bin",
    "handler": "handler.py",
    "modelVersion": "1.0"
  },
  "archiverVersion": "0.7.0"
}
```

### TorchServe ë°°í¬í•˜ê¸°

ì´ì œ ëª¨ë¸ì„ ë°°í¬í•  ì¼ë§Œ ë‚¨ì•˜ìŠµë‹ˆë‹¤. ì‹¤í–‰ì— ì•ì„œ `torch_model`í´ë”ì— model_store í´ë”ë¥¼ ë§Œë“  ë’¤ bert-model.mar íŒŒì¼ì„ ë‚´ë¶€ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.

<img src='/assets/blog/mlops/torchserve/img5.png' alt='img5'>

<br/>
<br/>

ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ Torchserveë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `--model-store`ëŠ” í´ë” ê²½ë¡œ, `--models`ì€ `ëª¨ë¸ëª…`ê³¼ MarFileì„ ì„¤ì •í•©ë‹ˆë‹¤. `ëª¨ë¸ëª…`(ì˜ˆì œì—ì„œëŠ” bert)ì€ API Endpointë¡œ í™œìš©ë˜ë¯€ë¡œ ê¸°ì–µí•´ì£¼ì…”ì•¼í•©ë‹ˆë‹¤.

```bash
torchserve --start --model-store model_store --models bert=bert-model.mar
```

<br/>

> ëª¨ë¸ ì‹¤í–‰ ì¤‘ ì¤‘ snapshot is emptyë¡œ ëœ¨ê³  ì¢…ë£Œë˜ëŠ” ê²½ìš° `--no-config-snapshots`ì„ ì¶”ê°€ë¡œ í¬í•¨í•´ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.
> <img src='/assets/blog/mlops/torchserve/img6.png' alt='img6' >

<br/>

ì´ì œ ìƒˆë¡œìš´ Terminalì„ ë„ìš°ê³  APIì— ì ‘ê·¼í•´ë³´ê² ìŠµë‹ˆë‹¤. torchserveì—ì„œ ì‚¬ìš©í–ˆë˜ `ëª¨ë¸ëª…`ì„ í™œìš©í•´ ì£¼ì†Œë¥¼ http://127.0.0.1:8080/predictions/ëª¨ë¸ëª… ìœ¼ë¡œ ë³€ê²½í•´ì•¼í•©ë‹ˆë‹¤.

```bash
curl -X POST -H "Content-Type: text/plain"  http://127.0.0.1:8080/predictions/bert -d "Stopped back by Mellow Mushroom with my mate Justin from Brew Bros."

ê²°ê³¼ : 2
```

Torchserveê°€ ì¼œì§„ í™˜ê²½ì„ ë³´ë©´ ì´ì™€ ê°™ì´ Input dataê°€ ì •í™•íˆ ë“¤ì–´ì™”ìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<img src='/assets/blog/mlops/torchserve/img7.png' alt='img7' >

### Debuggingì„ ìœ„í•œ Shell script ìƒì„±

ë°°í¬ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ë ¤ë©´ Torchserveë¥¼ ì¢…ë£Œí•˜ê³ , handler.pyë¥¼ ìˆ˜ì •í•œ ë‹¤ìŒ ë‹¤ì‹œ MAR fileì„ ìƒì„±í•˜ëŠ” ë°˜ë³µë˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼í•©ë‹ˆë‹¤.

ë””ë²„ê¹…ì„ í¸ë¦¬í•˜ê²Œ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ shell scriptë¥¼ í™œìš©í•©ì‹œë‹¤. ì•„ë˜ ë‚´ìš©ì„ ë³µì‚¬í•´ì„œ `debug_torch.sh` íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”. `torch-model` í´ë”ì— ë„£ì€ ë‹¤ìŒ `chmod -x 'debug_torch.sh`ë¥¼ ì‹¤í–‰í•´ ê¶Œí•œì„ ë³€ê²½í•œ ë’¤ `debug_torch.sh`ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.

```bash
#!/bin/bash

torchserve --stop

model_name="bert-model"

# mar ë§Œë“¤ê¸°
torch-model-archiver --model-name ${model_name} --version 1.0 --serialized-file pytorch_model.bin  --handler "handler.py" --extra-files "config.json,vocab.txt" --force

echo 'MAR File ìƒì„± ì™„ë£Œ'

mv -f ${model_name}.mar model_store

ì‹¤í–‰í•˜ê¸°
torchserve --start --model-store model_store --models bert=bert-model.mar --no-config-snapshots

```
