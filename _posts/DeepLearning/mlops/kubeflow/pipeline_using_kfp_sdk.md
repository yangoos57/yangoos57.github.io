---
publish: false
title: "[Kubeflow] ëª¨ë¸ í•™ìŠµë¶€í„° ì„œë¹™ê¹Œì§€ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•í•˜ê¸°"
date: "2023-01-26"
category: ["ML ops", "kubeflow"]
thumbnail: "/assets/blog/mlops/kubeflow/thumbnail.png"
ogImage:
  url: "/assets/blog/mlops/kubeflow/thumbnail.png"
desc: "ì´ ê¸€ì€ kuebeflow Pipeline(kfp)ë¥¼ í™œìš©í•´ pytorch ëª¨ë¸ í•™ìŠµë¶€í„° ì„œë¹™ê¹Œì§€ ì „ ê³¼ì •ì„ ìë™í™”í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ëª¨ë¸ í•™ìŠµì—ëŠ” huggingfaceì˜ Transformersë¥¼ í™œìš©í•˜ë©° ëª¨ë¸ ì„œë¹™ì—ëŠ” Torch serve, kserveë¥¼ í™œìš©í•©ë‹ˆë‹¤. í•´ë‹¹ íˆ´ì— ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš° ì•„ë˜ì˜ ë§í¬ë¥¼ ë¨¼ì € ì½ì€ ë‹¤ìŒ ì´ ê¸€ì„ ì½ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤."
---

### ë“¤ì–´ê°€ë©°

ì´ ê¸€ì€ kuebeflow íŒŒì´í”„ë¼ì¸ë¥¼ í™œìš©í•´ ëª¨ë¸ í•™ìŠµë¶€í„° ì„œë¹™ê¹Œì§€ ìë™í™”í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì— í•„ìš”í•œ ëª¨ë¸ ë° ì„œë¹™ ë°©ë²•ì€ ì•„ë˜ ë§í¬ì—ì„œ ì„¤ëª…í•œ ì˜ˆì œë¥¼ í™œìš©í•  ì˜ˆì •ì´ë¯€ë¡œ ì—°ê²°ëœ ê¸€ì„ ë¨¼ì € ì½ì€ ë‹¤ìŒ ì´ ê¸€ì„ ì½ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

- [ğŸ¤— Transformersë¥¼ í™œìš©í•´ Torchserve ë°°í¬í•˜ê¸°](https://yangoos57.github.io/blog/mlops/torchserve/Deploying_torchserve_using_transformers/)

- [Kserveë¡œ pytorch ëª¨ë¸ ì„œë¹™í•˜ê¸°](https://yangoos57.github.io/blog/mlops/kubeflow/Serving_torch_model_using_kserve/)

<br/>

ì´ë²ˆ ì˜ˆì œì—ì„œ êµ¬í˜„í•˜ê³ ì í•˜ëŠ” íŒŒì´í”„ë¼ì¸ì€ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì€ íë¦„ì„ ê°€ì§‘ë‹ˆë‹¤. ëª¨ë“  ë‹¨ê³„ëŠ” kubeflowì˜ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ìˆ˜í–‰ë˜ë©°, ìˆ˜í–‰ ê³¼ì •ì€ í•™ìŠµ í‰ê°€ ë°ì´í„° í™•ë³´, ëª¨ë¸ í•™ìŠµ, ì„œë¹™ì— í•„ìš”í•œ ë°ì´í„° ìƒì‚°, ì„œë¹™ ìˆœì…ë‹ˆë‹¤. ì´ë•Œ ê°œë³„ ì»´í¬ë„ŒíŠ¸ì˜ ê²°ê³¼ë¬¼ì€ ì‚¬ì „ ì„¤ì •í•œ Storageì— ì €ì¥ë˜ë©° ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ê³ , íŒŒì´í”„ë¼ì¸ ì™¸ë¶€ì—ì„œë„ ê²°ê³¼ë¬¼ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•  ì˜ˆì •ì…ë‹ˆë‹¤.

<img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img1.png' alt='img1'>

<br/>
<br/>

### KFP SDK ì´í•´í•˜ê¸°

KFP SDKëŠ” kubeflow íŒŒì´í”„ë¼ì¸ì„ pythonì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. KFP SDKë¥¼ í™œìš©í•˜ë©´ kubeflow íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì—ì„œ ë°œìƒí•˜ëŠ” ë²ˆê±°ë¡œìš´ ê³¼ì •ì„ ìƒëµí•  ìˆ˜ ìˆì–´ ì„œë¹™ë¶€í„° ë°°í¬ê¹Œì§€ ëª¨ë“  ê³¼ì •ì„ í¸ë¦¬í•˜ê²Œ ì§„í–‰ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

KFP SDK ì„¤ëª…ì— ì•ì„œ KFP SDKë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  kubeflowì˜ íŒŒì´í”„ë¼ì¸ì„ í™œìš©í•˜ëŠ” ì¼ì´ ì–¼ë§ˆë‚˜ ë²ˆê±°ë¡œìš´ ì¼ì¸ì§€ì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ê·¸ë¦¼ì€ KFP SDKë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì‚¬ìš©ìê°€ ì–´ë–»ê²Œ kubeflow íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•´ì•¼í•˜ëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

<img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img2.png' alt='img2'>

ì‚¬ìš©ìëŠ” íŒŒì´í”„ë¼ì¸ì—ì„œ ì‹¤í–‰ë  ì½”ë“œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ê´€ë ¨ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ì»¨í…Œì´ë„ˆ ë¹Œë“œë¥¼ ìœ„í•´ ë„ì»¤íŒŒì¼ì„ ì‘ì„±í•˜ê³  ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë¹Œë“œí•œ ì»¨í…Œì´ë„ˆë¥¼ kubeflow íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ë™í•˜ê¸° ìœ„í•´ì„  ARGO CRDì— ë§ëŠ” ì–‘ì‹ìœ¼ë¡œ yaml íŒŒì¼ì„ ì‘ì„±í•´ì•¼í•©ë‹ˆë‹¤. yaml íŒŒì¼ê¹Œì§€ ì‘ì„±í–ˆë‹¤ë©´ ì´ì œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•´ Kubeflow dashboardì—ì„œ íŒŒì´í”„ë¼ì¸ì„ ë“±ë¡í•´ì•¼í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì„ ë“±ë¡í•˜ê¸° ìœ„í•´ì„  Experimentë¥¼ ìƒì„±ì´ í•„ìš”í•˜ë¯€ë¡œ Kubeflow dashboard Experiment í•­ëª©ì—ì„œ ì´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ë“±ë¡ê¹Œì§€ ë§ˆì³¤ë‹¤ë©´ ë§ˆì§€ë§‰ìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ìœ„í•´ Kubeflow dashboardì˜ RUN í•­ëª©ìœ¼ë¡œ ë„˜ì–´ê°€ ì‹¤í–‰í•©ë‹ˆë‹¤.

> KFP SDK ì‚¬ìš©ì—†ì´ ì¿ ë²„ë„¤í‹°ìŠ¤ë¡œ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œë¥¼ ì•Œê³ ì‹¶ë‹¤ë©´ [titanic-kaggle-competition ì˜ˆì œ](https://github.com/kubeflow/examples/tree/master/titanic-kaggle-competition)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

<br/>
<br/>

ì´ëŸ° ê³¼ì •ì„ í•œ ë‘ ë²ˆ ì •ë„ ê²½í—˜í•˜ëŠ” ê²ƒì€ ê·¸ë‹¤ì§€ ë¶ˆí¸í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë””ë²„ê¹…ì„ í•´ì•¼í•˜ëŠ” ìƒí™©ì´ë‚˜ ë¹ ë¥´ê²Œ í•™ìŠµí•˜ê³  ë°°í¬í•´ì•¼ í•˜ëŠ” ê³¼ì •ì—ì„œ ì´ ê³¼ì •ì„ ìˆ˜ì‹­ë²ˆì„ ë„˜ê²Œ ë°˜ë³µ í•œë‹¤ë©´ ì´ê²ƒë§Œí¼ì˜ ë¹„íš¨ìœ¨ì€ ì—†ì„ ê²ë‹ˆë‹¤. KFP SDKëŠ” ì´ëŸ¬í•œ ë²ˆê±°ë¡œìš´ ì‘ì—…ì„ ëª‡ ì¤„ì˜ ì½”ë“œë¡œ ìë™í™” í•  ìˆ˜ ìˆìœ¼ë©° ëª¨ë¸ ì„œë¹™ë‹¨ê³„ê¹Œì§€ë„ í•œ ë²ˆì˜ ì‹¤í–‰ìœ¼ë¡œ ì™„ë£Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì§€ê¸ˆë¶€í„°ëŠ” KFP SDKê°€ ì–´ë– í•œ ë°©ì‹ìœ¼ë¡œ ì‘ë™ë˜ëŠ”ì§€, ì–´ë–»ê²Œ ë¶ˆí•„ìš”í•œ ì‘ì—…ì„ ì¤„ì—¬ì£¼ëŠ”ì§€ì— ëŒ€í•´ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

#### â– íŒŒì´ì¬ ì½”ë“œë¥¼ ì»´í¬ë„ŒíŠ¸ë¡œ

KFP SDKë¥¼ ì ‘í•˜ë©´ ê°€ì¥ ë¨¼ì € ë°°ìš°ëŠ” ë§¤ì„œë“œëŠ” `func_to_container_op`ì™€ `create_component_from_func` ì¼ ê²ƒì…ë‹ˆë‹¤. `func_to_container_op`ì™€ `create_component_from_func`ì€ ì•ì„œ ì„¤ëª…ì—ì„œ íŒŒì´ì¬ ì½”ë“œë¥¼ ë„ì»¤ ì»¨í…Œì´ë„ˆë¡œ ë¹Œë“œí•˜ëŠ” ë‹¨ê³„ì— ëŒ€ì‘ë˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì´ ë§¤ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ py íŒŒì¼ì„ ë§Œë“  ë‹¤ìŒ ì¼ì¼ì´ ì´ë¯¸ì§€ë¡œ ë§Œë“¤ì—ˆë˜ ì‘ì—…ì„ ìƒëµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. KFP SDKë¡œ íŒŒì´í”„ë¼ì¸ì„ compileí•œ yaml íŒŒì¼ì„ ë³´ì‹ ë¶„ë“¤ì€ ì•„ì‹œê² ì§€ë§Œ, ì»´í¬ë„ŒíŠ¸ë¡œ ê°ì‹¸ì—¬ì§„ íŒŒì´ì¬ ì½”ë“œëŠ” ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ python ëª…ë ¹ì–´ì— argumentsë¥¼ ë¶™ì—¬ë„£ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ë™ë©ë‹ˆë‹¤.

ì´ ë°©ì‹ì€ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë‹¨ê³„ë¥¼ ìƒëµí•œë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ ì•½ê°„ì˜ ë‹¨ì (?)ë„ ì¡´ì¬í•©ë‹ˆë‹¤. resource requests,resource limits, volume mountì™€ ê°™ì´ ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ì‹œ ì„¤ì •í•˜ëŠ” ê°’ì„ `create_component_from_func`ì™€ `func_to_container_op`ë¡œëŠ” ì„¤ì •í•  ìˆ˜ ì—†ë‹¤ëŠ” ì ì…ë‹ˆë‹¤. ì˜ˆë¡œë“¤ì–´ `create_component_from_func` ë§¤ì„œë“œëŠ” packages_to_install, base_image, annotations ë§Œì„ ì§€ì›í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ì´ëŸ¬í•œ ë§¤ì„œë“œë¥¼ ì‚¬ìš©í•  ë•Œ resource requests,resource limits, volume mountëŠ” ê°™ì€ ì„¸ë¶€ì ì¸ ì˜µì…˜ì€ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ê·¸ë ‡ë‹¤ë©´ resource requests,resource limits, volume mount ê°™ì€ ì¿ ë²„ë„¤í‹°ìŠ¤ ì„¤ì •ì€ ì–´ë–»ê²Œ ì»´í¬ë„ŒíŠ¸ì— ì ìš©í•´ì•¼í• ê¹Œìš”?

ë¨¼ì € ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ ë´…ì‹œë‹¤.

```python
from kfp.components import create_component_from_func,func_to_container_op
@create_component_from_func
def test_component():
	pass

@func_to_container_op
def test_container_op():
	pass

print(type(test_component()))
print(type(test_container_op()))

>>> <class 'kfp.components._structures.TaskSpec'>
>>> <class 'kfp.components._structures.TaskSpec'>

```

í•¨ìˆ˜ ì‹¤í–‰ê²°ê³¼ ë‘ í•¨ìˆ˜ì˜ íƒ€ì…ì´ `kfp.components._structures.TaskSpec`ë¡œ ë™ì¼í•œ ê²ƒì„ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `kfp.components._structures.TaskSpec` íƒ€ì…ì€ íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë˜ë©´ `kfp.dsl.ContainerOp` í´ë˜ìŠ¤ì˜ ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì¦‰ `create_component_from_func`ë¡œ ìƒì„±í•œ ì»´í¬ë„ŒíŠ¸ëŠ” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œ `kfp.components._structures.TaskSpec`ì„ ê±°ì³ `kfp.dsl.ContainerOp` í´ë˜ìŠ¤ë¡œ ë³€í™˜ë˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê·¸ë ‡ë‹¤ë©´ `create_component_from_func`ëŠ” ì™œ `kfp.dsl.ContainerOp` í´ë˜ìŠ¤ë¡œ ë³€í™˜ë˜ëŠ” ê±¸ê¹Œìš”?
ê·¸ ì´ìœ ëŠ” ìš°ë¦¬ê°€ ì•ì„œ ê¶ê¸ˆí•´í–ˆë˜ resource requests,resource limits, volume mount ê°™ì€ ì¿ ë²„ë„¤í‹°ìŠ¤ ì˜µì…˜ì„ `kfp.dsl.ContainerOp` í´ë˜ìŠ¤ë¥¼ í†µí•´ ì„¤ì •í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
ì´ê²Œ ê°€ëŠ¥í•œ ì´ìœ ëŠ”`ContainerOp` í´ë˜ìŠ¤ê°€ ì¿ ë²„ë„¤í‹°ìŠ¤ SDKì˜ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ì¸ `V1container`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„ëê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë”°ë¼ì„œ ContainerOp ë‚´ë¶€ì—ì„œ ìµœì¢…ì ìœ¼ë¡œ ì¿ ë²„ë„¤í‹°ìŠ¤ SDKë¥¼ í™œìš©í•˜ë¯€ë¡œ ì¿ ë²„ë„¤í‹°ìŠ¤ ì„¤ì • ê°’ì„ ì ìš©í•  ìˆ˜ ìˆê²Œë˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

<img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img3.png' alt='img3'>

<br/>

#### â– ì»´í¬ë„ŒíŠ¸ë¥¼ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ êµ¬ì¶•

íŒŒì´í”„ë¼ì¸ì€ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ê°ì‹¸ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤. ê·¸ë¦¬ê³  ì´ íŒŒì´í”„ë¼ì¸ì€ argoë¼ëŠ” workflow ìœ„ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ ë‚´ë¶€ì˜ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ëŠ” `kfp.dsl.ContainerOp` í´ë˜ìŠ¤ë¡œ ë³€í™˜ëœ ìƒíƒœì´ë©° `ContainerOp` í´ë˜ìŠ¤ì—ì„œëŠ” ì»´í¬ë„ŒíŠ¸ì— ì¿ ë²„ë„¤í‹°ìŠ¤ ì„¤ì • ê°’ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `ContainerOp`ì€ ì¿ ë²„ë„¤í‹°ìŠ¤ ì„¤ì • ì™¸ì—ë„ argo ì‹¤í–‰ì‹œ í™œìš©ë˜ëŠ” ì„¤ì • ê°’ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¡œë“¤ë©´ ì»´í¬ë„ŒíŠ¸ì˜ ì‹¤í–‰ ìˆœì„œë¥¼ ì„¤ì •í•˜ëŠ” `after`, íŒŒì´í”„ë¼ì¸ UIì— í‘œí˜„ëœ ì»´í¬ë„ŒíŠ¸ì— ëŒ€í•œ ì„¤ëª…ì„ ë³€ê²½í•  ìˆ˜ ìˆëŠ” `set_display_name` ë§¤ì„œë“œê°€ ê·¸ëŸ¬í•©ë‹ˆë‹¤.

<img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img4.png' alt='img4'>

<br/>

#### â– íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼

íŒŒì´í”„ë¼ì¸ êµ¬ë™ì— í•„ìš”í•œ ëª¨ë“  ì„¸íŒ…ì„ ì™„ë£Œí–ˆë‹¤ë©´ KFPë¥¼ ì‹¤ì œ ì´ìš©í•˜ê¸° ìœ„í•´ì„œ íŒŒì´ì¬ ì½”ë“œë¥¼ yaml íŒŒì¼ë¡œ ì»´íŒŒì¼í•˜ëŠ” ê³¼ì •ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤. ë¬¼ë¡  KFP SDKì„ í™œìš©í•˜ë©´ ë³„ë‹¤ë¥¸ ìˆ˜ê³ ì—†ì´ yaml íŒŒì¼ì„ ì†ì‰½ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìëŠ” íŒŒì´í”„ë¼ì¸ ìƒì„±, êµ¬ë™ì— í•„ìš”í•œ yaml íŒŒì¼ ìƒì„±ì„ KFP SDKë¥¼ í†µí•´ ìë™í™” í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ìœ¼ë¡œ í•´ì•¼í•  ê³¼ì •ì€ yaml íŒŒì¼ì„ Kubeflow dashboardì— ìˆëŠ” Pipeline í•­ëª©ì— ì—…ë¡œë“œí•˜ê³ , Experiment í•­ëª©ìœ¼ë¡œ ì´ë™í•´ Experimentë¥¼ ìƒì„±í•œ ë’¤ ì‹¤í–‰ ë²„íŠ¼ì„ ëˆ„ë¥´ëŠ” ê²ƒë§Œ ìˆ˜í–‰í•˜ë©´ ë©ë‹ˆë‹¤. ì´ ëª¨ë“  ê³¼ì •ì€ kubeflow UIì—ì„œ ì§„í–‰ë˜ë¯€ë¡œ ì§ê´€ì ì´ê³  ì–´ë µì§€ì•Šì€ ê³¼ì •ì…ë‹ˆë‹¤.

í•˜ì§€ë§Œ ì´ëŸ¬í•œ í¸ë¦¬í•¨ë„ íŒŒì¼ ìˆ˜ì •, ì—…ë¡œë“œ ì‹¤í–‰ ê³¼ì •ì„ ìˆ˜ì‹­ë²ˆ ë°˜ë³µí•˜ë‹¤ë³´ë©´ ìƒë‹¹íˆ ê³ í†µìŠ¤ëŸ½ê³ , ë¹„íš¨ìœ¨ì ìœ¼ë¡œ ëŠê»´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤í–‰ì´ë„ KFP SDKì—ëŠ” íŒŒì´í”„ë¼ì¸ì„ ìë™ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” ë°©ë²• ë˜í•œ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ì„ í†µí•´ì„œ ë‚˜ë¨¸ì§€ í•´ì•¼ í•  ì¼ë„ ìë™í™”ë¡œ ì§„í–‰í•´ ë³´ê² ìŠµë‹ˆë‹¤.

<img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img5.png' alt='img5'>

<br/>

#### â– kfp clientë¡œ íŒŒì´í”„ë¼ì¸ ë°°í¬

kfp.clientë¥¼ í™œìš©í•˜ë©´ experiment ìƒì„±, íŒŒì´í”„ë¼ì¸ì— yaml íŒŒì¼ ì—…ë¡œë“œ, íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë‹¨ê³„ë¥¼ ìë™í™” í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì™¸ì—ë„ clientëŠ” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë¿ë§Œì•„ë‹ˆë¼ ëª¨ë‹ˆí„°ë§, ì‚­ì œ, ë³´ê´€(archive) ë“± íŒŒì´í”„ë¼ì¸ì„ ê´€ë¦¬í•˜ëŠ” ê¸°ëŠ¥ë„ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.

<img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img6.png' alt='img6'>

<br/>
<br/>

### í•™ìŠµë¶€í„° ì„œë¹™ê¹Œì§€ íŒŒì´í”„ë¼ì¸ êµ¬í˜„

ì§€ê¸ˆê¹Œì§€ KFP SDKë¥¼ ì™œ í™œìš©í•´ì•¼í•˜ëŠ”ì§€, ê¸°ë³¸ ê°œë…, ì¼ë¶€ í´ë˜ìŠ¤ì— ëŒ€í•´ì„œ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤. ì´ì œëŠ” ì§ì ‘ KFP SDKë¥¼ í™œìš©í•´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì€ workflowë¥¼ ê°€ì§„ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•´ë³´ê² ìŠµë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì˜ˆì œì— í™œìš©ëœ ëª¨ë¸ì€ [ğŸ¤— Transformersë¥¼ í™œìš©í•´ Torchserve ë°°í¬í•˜ê¸°](https://yangoos57.github.io/blog/mlops/torchserve/Deploying_torchserve_using_transformers/)ì—ì„œ ì„¤ëª…í–ˆë˜ ëª¨ë¸ì„ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” ëª¨ë¸ì— ê´€í•œ ì„¤ëª…ì„ í¬í•¨í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ëª¨ë¸ê³¼ ê´€ë ¨ëœ ì½”ë“œê°€ ê¶ê¸ˆí•œ ê²½ìš° ë§í¬ë¥¼ ì°¸ê³ ë°”ëë‹ˆë‹¤.

<img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img1.png' alt='img1'>

<br/>

#### â– í•™ìŠµ í‰ê°€ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ì— í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ í•˜ë‚˜ì”© êµ¬í˜„í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¨¼ì € ì™¸ë¶€ì— ìˆëŠ” í•™ìŠµ, í‰ê°€ ë°ì´í„°ë¥¼ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜®ê¸°ëŠ” ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ëŠ” ğŸ¤— Transformersë¥¼ í™œìš©í•´ Torchserve ë°°í¬í•˜ê¸°ì—ì„œ í™œìš©í–ˆë˜ yelp review dataë¥¼ ë¶ˆëŸ¬ì˜¤ê² ìŠµë‹ˆë‹¤.

ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì€ ë‹¤ì–‘í•˜ì§€ë§Œ ì´ ê¸€ì—ì„œëŠ” github repoì— ì—…ë¡œë“œí•œ train.csv íŒŒì¼ê³¼ valtidation.csv íŒŒì¼ì„ pandas `read_csv` ë§¤ì„œë“œë¥¼ í†µí•´ ë¶ˆëŸ¬ì˜¤ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ì´ë•Œ ë‹¤ìš´ë°›ì€ ë°ì´í„°ëŠ” PVCì— ì €ì¥í•´ì„œ ë‹¤ìŒ ì»´í¬ë„ŒíŠ¸ì—ì„œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•©ë‹ˆë‹¤. ì´ ê¸€ì—ì„  PVCë¥¼ í™œìš©í•  ì˜ˆì •ì´ë¯€ë¡œ ì €ì¥ ê²½ë¡œ ì„¤ì • ì‹œ `outputpath` ë§¤ì„œë“œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì¼ë°˜ì ì¸ ìƒëŒ€ ê²½ë¡œë¥¼ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤. PVCì™€ ì»´í¬ë„ŒíŠ¸ë¥¼ ì—°ê²°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ `íŒŒì´í”„ë¼ì¸ ìƒì„±` í•­ëª©ì—ì„œ ë‹¤ë£¨ê³  ìˆìŠµë‹ˆë‹¤.

> `outputpath`ë¥¼ ì‚¬ìš©í•˜ë©´ Minio ì €ì¥ì†Œì— ì €ì¥ë˜ë¯€ë¡œ ê°œë³„ ì»´í¬ë„ŒíŠ¸ì—ì„œ ìƒì„±í•œ ê²°ê³¼ë¬¼ë“¤ì„ ì™¸ë¶€ì—ì„œ í™•ì¸í•˜ê±°ë‚˜, ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ì—ì„œ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ëŠ”ë°ì— ì–´ë ¤ì›€ì´ ìˆìŠµë‹ˆë‹¤. PVCë¥¼ ìƒì„±í•´ ê°œë³„ ì»´í¬ë„ŒíŠ¸ì˜ ê²°ê³¼ë¬¼ì„ ê´€ë¦¬í•œë‹¤ë©´ ì»´í¬ë„ŒíŠ¸ì˜ ê²°ê³¼ë¬¼ë“¤ì„ Jupyterlabì—ì„œ ê°„í¸í•˜ê²Œ í™•ì¸í•  ìˆ˜ ìˆê³  ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ì—ì„œë„ ì†ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ë²ˆ ì˜ˆì œì—ì„œëŠ” PVCë¥¼ í™œìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤.

```python
from functools import partial
from kfp.components import create_component_from_func


@partial(
    create_component_from_func,
    packages_to_install=["pandas"],
)
def load_data():

    import pandas as pd
    import os

    # ê²½ë¡œ í™•ì¸ ìš©
    print("list_dir : \n ", os.listdir())

    # load data from github
    df_train = pd.read_csv(
        "https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/train.csv"
    )
    df_evaluation = pd.read_csv(
        "https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/validation.csv"
    )

    df_train.to_csv("pvc/train.csv", index=False)
    df_evaluation.to_csv("pvc/evaluation.csv", index=False)

    print("complete Loading Data")

```

<br/>

#### â– ëª¨ë¸ í•™ìŠµ ë° ëª¨ë¸ íŒŒì¼ì„ ì €ì¥í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

ë‘ë²ˆì§¸ ì»´í¬ë„ŒíŠ¸ëŠ” ëª¨ë¸ì„ í•™ìŠµí•˜ê³  & Mar file ìƒì„±ì— í•„ìš”í•œ íŒŒì¼ì„ pvcì— ì €ì¥í•˜ëŠ” ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ë¨¼ì € ğŸ¤— Transformersë¥¼ í™œìš©í•´ Text classification ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤. í•™ìŠµì´ ì™„ë£Œë˜ë©´ Mar file ìƒì„±ì— í•„ìš”í•œ íŒŒì¼ì¸ Model íŒŒì¼, Tokenizer íŒŒì¼, handler.py, config.propertiesì„ pvcì— ì €ì¥í•©ë‹ˆë‹¤.

> ë³„ë„ì˜ íŒŒì¼ ì—…ë¡œë“œ & ë‹¤ìš´ë¡œë“œ ê³¼ì •ì„ ìƒëµí•˜ê¸° ìœ„í•´ handler.pyì™€ config.propertiesëŠ” ì½”ë“œë¥¼ ë¶™ì—¬ë„£ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

```python
@partial(create_component_from_func, base_image="679oose/python_huggingface")
def train_model():

    from transformers import (
        DistilBertForSequenceClassification,
        DistilBertTokenizer,
        Trainer,
        TrainingArguments,
        TrainerCallback,
    )

    from datasets import Dataset

    import os

    # ê²½ë¡œ í™•ì¸ ìš©
    print("list_dir : \n ", os.listdir())
    print("list_dir : \n ", os.getcwd())
    os.chdir("/")

    train_dataset = Dataset.from_csv("pvc/train.csv").select(range(32))
    evaluation_dataset = Dataset.from_csv("pvc/evaluation.csv")

    # tokenizing
    tokenizer = DistilBertTokenizer.from_pretrained("distilbert-base-uncased")

    def tokenize_function(item):
        return tokenizer(item["text"], padding="max_length", max_length=128, truncation=True)

    train = train_dataset.map(tokenize_function)
    evaluation = evaluation_dataset.map(tokenize_function)

    print("complete Tokenizing")

    model = DistilBertForSequenceClassification.from_pretrained(
        "distilbert-base-uncased", num_labels=len(set(train_dataset["label"]))
    )

    tra_arg = TrainingArguments(
        per_device_train_batch_size=8,
        output_dir="test",
        num_train_epochs=1,
        logging_steps=2,
        # evaluation_strategy="epoch",
        disable_tqdm=True,
        save_strategy="no",
    )

    class myCallback(TrainerCallback):
        def on_log(self, args, state, control, logs=None, **kwargs):
            print(f"{state.global_step} Steps ")

    trainer = Trainer(
        model=model,
        args=tra_arg,
        train_dataset=train,
        eval_dataset=evaluation,
        callbacks=[myCallback],
    )

    trainer.train()

    # Saving Tokenizer, Model
    trainer.save_model("pvc/torch_model")
    tokenizer.save_pretrained("pvc/torch_model")

    print("Saving Model & Tokenizer Complete !!")

    # config for torchserve
    import json
    config = dict(
        inference_address="http://0.0.0.0:8085",
        management_address="http://0.0.0.0:8085",
        metrics_address="http://0.0.0.0:8082",
        grpc_inference_port=7070,
        grpc_management_port=7071,
        enable_envvars_config="true",
        install_py_dep_per_model="true",
        model_store="model-store",
        model_snapshot=json.dumps({
            "name": "startup.cfg",
            "modelCount": 1,
            "models": {
                "torch-model": {  # Model Name
                    "1.0": {
                        "defaultVersion": "true",
                        "marName": "torch-model.mar",
                        "minWorkers": 1,
                        "maxWorkers": 5,
                        "batchSize": 1,
                        "maxBatchDelay": 10,
                        "responseTimeout": 60,
                    }
                }
            },
        }),
    )

    # creating config & config folder
    if not os.path.exists("pvc/torch_model/config"):
        os.mkdir("pvc/torch_model/config")

    with open("pvc/torch_model/config/config.properties", "w") as f:
        for i, j in config.items():
            f.write(f"{i}={j}\n")
        f.close()

    print("Saving config.properties !!")

    # handler for torchserve
    x = '''
from abc import ABC
import json
import logging
import os

import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from ts.torch_handler.base_handler import BaseHandler

logger = logging.getLogger(__name__)


class TransformersClassifierHandler(BaseHandler, ABC):
    def __init__(self):
        super(TransformersClassifierHandler, self).__init__()
        self.initialized = False

    def initialize(self, ctx):
        self.manifest = ctx.manifest

        properties = ctx.system_properties
        model_dir = properties.get("model_dir")
        self.device = torch.device(
            "cuda:" + str(properties.get("gpu_id")) if torch.cuda.is_available() else "cpu"
        )

        # Read model serialize/pt file
        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)

        self.model.to(self.device)
        # BetterTransformer
        self.model.eval()

        logger.debug(f"Transformer model from path {model_dir} loaded successfully")

        # Read the mapping file, index to object name
        mapping_file_path = os.path.join(model_dir, "index_to_name.json")

        if os.path.isfile(mapping_file_path):
            with open(mapping_file_path) as f:
                self.mapping = json.load(f)
        else:
            logger.warning(
                "Missing the index_to_name.json file. Inference output will not include class name."
            )

        self.initialized = True

    def preprocess(self, data):
        """Very basic preprocessing code - only tokenizes.
        Extend with your own preprocessing steps as needed.
        """
        print("------- input data --------")
        print(data)
        text = data[0].get("data")
        if text is None:
            text = data[0].get("body")

        logger.info(f"Received text: {text}")

        inputs = self.tokenizer.encode_plus(text, add_special_tokens=True, return_tensors="pt")
        return inputs

    def inference(self, inputs):
        """
        Predict the class of a text using a trained transformer model.
        """
        # NOTE: This makes the assumption that your model expects text to be tokenized
        # with "input_ids" and "token_type_ids" - which is true for some popular transformer models, e.g. bert.
        # If your transformer model expects different tokenization, adapt this code to suit
        # its expected input format.
        inputs = inputs.to(self.device)

        prediction = self.model(**inputs)[0].argmax().item()
        logger.info(f"Model predicted: {prediction}")

        if self.mapping:
            prediction = self.mapping[str(prediction)]
        return [prediction]

    def postprocess(self, inference_output):
        # TODO: Add any needed post-processing of the model predictions here
        logger.info(f"Model Name: {self.model.config._name_or_path}")
        logger.info(f"Model predicted: {inference_output}")
        return inference_output


_service = TransformersClassifierHandler()


def handle(data, context):
    try:
        if not _service.initialized:
            _service.initialize(context)

        if data is None:
            return None

        data = _service.preprocess(data)
        data = _service.inference(data)
        data = _service.postprocess(data)

        return data
    except Exception as e:
        raise e


    '''
    with open("pvc/torch_model/handler.py", "w") as f:
        f.write(x)
    f.close()

    print("Saving handler.py complete !!")

```

<br/>

#### â– mar fileì„ ìƒì„±í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

pvcì— ì €ì¥ëœ íŒŒì¼ì„ í™œìš©í•´ TorchServe êµ¬ë™ì— í•„ìš”í•œ Mar fileì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤. Mar file ìƒì„±ì€ bashì—ì„œ python ëª…ë ¹ì–´ë¡œ ì‹¤í–‰í•˜ë¯€ë¡œ `create_component_from_func` ì™€ ê°™ì€ ë§¤ì„œë“œ ëŒ€ì‹  `ContainerOp`ì„ ì§ì ‘ ë¶ˆëŸ¬ì™€ ì‚¬ìš©í•©ë‹ˆë‹¤. bash ëª…ë ¹ì–´ëŠ” pvc/torch_model ê²½ë¡œë¡œ ì´ë™ => Torchserve ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ => torch-model-archiver ì‹¤í–‰ ìˆœìœ¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.

```python

from kfp.dsl import ContainerOp


def create_marfile():
    return ContainerOp(
        name="Creating Marfile",
        command=["/bin/sh"],
        image="python:3.9",
        arguments=[
            "-c",
            "cd pvc/torch_model; pip install torchserve torch-model-archiver torch-workflow-archiver; torch-model-archiver --model-name torch-model --version 1.0 --serialized-file pytorch_model.bin --handler handler.py --extra-files config.json,vocab.txt --force; mkdir model-store; mv -f torch-model.mar model-store"
        ],  # pip install => create mar file => make model_store folder => mv marfile to model_store
    )

```

<br/>

#### â– ëª¨ë¸ì„ ì„œë¹™í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ êµ¬í˜„

íŒŒì´í”„ë¼ì¸ì—ì„œ ì„œë¹™ ëª¨ë¸ì„ ë°°í¬í•˜ê¸° ìœ„í•´ì„  ìœ„í•´ì„  kserve clientë¥¼ ì‚¬ìš©í•´ì•„í•©ë‹ˆë‹¤. kserve clientë¥¼ í™œìš©í•´ ì§ì ‘ ì»´í¬ë„ŒíŠ¸ë¥¼ êµ¬í˜„í•˜ëŠ” ë°©ë²•ë„ ìˆì§€ë§Œ, ì´ë¯¸ ë§Œë“¤ì–´ì ¸ìˆëŠ” [Kserve component](https://github.com/kubeflow/pipelines/tree/master/components/kserve)ë¥¼ í™œìš©í•˜ê² ìŠµë‹ˆë‹¤. ì‚¬ìš©í•  componentëŠ” kubeflow Github í˜ì´ì§€ì— ì—…ë¡œë“œ ë˜ì–´ìˆìŠµë‹ˆë‹¤.

> kserve componentëŠ” kserve 0.7.0 ë²„ì „ì„ ì‚¬ìš©í•˜ì§€ë§Œ kubeflow 1.6.1 ë²„ì „ì—ì„œ ì—ëŸ¬ì—†ì´ ì •ìƒ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

kserve_componentë¥¼ í™œìš©í•´ ëª¨ë¸ëª…, namespace, marfileì´ ì €ì¥ëœ ê²½ë¡œ, ì‚¬ìš©í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¥¼ ì¸ìë¡œ ë„£ìœ¼ë©´ ì„œë¹™í•˜ë ¤ëŠ” ëª¨ë¸ì„ ê°„ë‹¨í•˜ê²Œ ë°°í¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from kfp.components import load_component_from_url

def create_inference_model():
    kserve_op = load_component_from_url('https://raw.githubusercontent.com/kubeflow/pipelines/'
                                               'master/components/kserve/component.yaml')

    model_name = "torchserve"
    namespace = "kubeflow-user-example-com"
    model_uri = "pvc://leeway/torch_model"
    framework="pytorch"

    return kserve_op(action="apply",
              model_name=model_name,
              model_uri=model_uri,
              namespace=namespace,
              framework=framework)
```

<br/>

#### â– íŒŒì´í”„ë¼ì¸ ìƒì„±

ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ìƒì„±í–ˆìœ¼ë‹ˆ ì´ì œ í•˜ë‚˜ì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë¬¶ì–´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  ì»´í¬ë„ŒíŠ¸ ë‹¨ê³„ì—ì„œ ë„£ì§€ ëª»í•œ ì¿ ë²„ë„¤í‹°ìŠ¤ ì„¤ì •ê°’ì„ ê°œë³„ ì»´í¬ë„ŒíŠ¸ì— ì¶”ê°€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë“¤ì´ ê³µí†µì˜ storageë¥¼ ê°–ë„ë¡ kfp.onprem.mount_pvc ë§¤ì„œë“œë¥¼ ì ìš©í•©ë‹ˆë‹¤. kfp.onprem í´ë˜ìŠ¤ëŠ” On-promiseí™˜ê²½ êµ¬ì¶•ì— í•„ìš”í•œ ë‹¤ì–‘í•œ ë§¤ì„œë“œë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ì»´í¬ë„ŒíŠ¸ê°€ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰ë  ìˆ˜ ìˆë„ë¡ after ë§¤ì„œë“œë¡œ ì´ì–´ì„œ ìˆ˜í–‰ë  ì»´í¬ë„ŒíŠ¸ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì¼ë¶€ ì»´í¬ë„ŒíŠ¸ì—” resource limitì„ ë¶€ì—¬í•©ë‹ˆë‹¤.

> PVCëŠ” kubeflow dashboardì˜ volume í•­ëª©ì—ì„œ ë¨¼ì € ìƒì„±í•©ë‹ˆë‹¤.

```python
from kfp.dsl import ContainerOp, pipeline
from kfp import onprem


@pipeline(name="NLP_Pipeline")
def NLP_Pipeline():
    ### ë°ì´í„° ë¡œë“œ
    data = load_data()
    data.apply(onprem.mount_pvc(pvc_name="leeway", volume_name="test-lee", volume_mount_path="pvc"))


    ### ëª¨ë¸ í•™ìŠµ
    model = train_model()
    model.apply(onprem.mount_pvc(pvc_name="leeway", volume_name="test-lee", volume_mount_path="pvc"))
    model.set_cpu_limit(cpu="1").set_memory_limit(memory="2G")
    model.set_display_name("Finetuning Text Classification Model")
    model.after(data)


    ### Mar file ìƒì„±
    marfile = create_marfile()
    marfile.apply(onprem.mount_pvc(pvc_name="leeway", volume_name="test-lee", volume_mount_path="pvc"))
    marfile.set_display_name("Creating Marfile")
    marfile.execution_options.caching_strategy.max_cache_staleness = "P0D" # cache ì‚¬ìš©ì•ŠëŠ” ì˜¶ì…˜
    marfile.after(model)


    ### ëª¨ë¸ ì„œë¹™
    inference_model = create_inference_model()
    inference_model.apply(onprem.mount_pvc(pvc_name="leeway", volume_name="test-lee", volume_mount_path="pvc"))
    inference_model.after(marfile)
```

<br/>

### â– KFP Clientë¥¼ í™œìš©í•´ íŒŒì´í”„ë¼ì¸ ë°°í¬

KFP Clientë¥¼ í™œìš©í•´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰ì‹œí‚¤ê² ìŠµë‹ˆë‹¤. ì™¸ë¶€ ì£¼ì†Œ(localhost:8080)ë¥¼ í†µí•´ ì ‘ê·¼í•˜ëŠ” ì˜ˆì œì´ë¯€ë¡œ isti-ingressgatewayê°€ ê°œë°©ëœ ìƒíƒœì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.

> kubeflowì˜ jupyter notebookìœ¼ë¡œ íŒŒì´í”„ë¼ì¸ì„ ë°°í¬í•  ê²½ìš° ì½”ë“œ ë‚´ë¶€ì˜ Kubeflow endpointë¥¼ ë‚´ë¶€ ì£¼ì†Œ(Cluster IP)ë¡œ ë³€ê²½í•´ì„œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. jupyter notebookì—ì„œ kfpë¡œì˜ ì ‘ê·¼ì€ í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì—ì„œ ë‚´ë¶€ë¡œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ë¯€ë¡œ localhost:8080ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´ `Connection refused` ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.

> httpsë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° `cert_for_kubeflow` í™˜ê²½ë³€ìˆ˜ë¥¼ ì¸ì¦ì„œê°€ ìœ„ì¹˜í•œ ê²½ë¡œì— ë§ê²Œ ì¬ì„¤ì •í•´ì•¼í•©ë‹ˆë‹¤. ì¸ì¦ì„œ ì—†ì´ ìš°íšŒí•´ì„œ ì‚¬ìš©í•˜ëŠ” ê²½ìš° [kubeflow ì¸ì¦ ë¬¸ì œ í•´ê²°í•˜ê¸°](https://yangoos57.github.io/blog/mlops/kubeflow/kubeflow_authorization/)ë¥¼ ì°¸ê³ í•´ ì„œë²„ í†µì‹ ì— í•„ìš”í•œ ì¸ì¦ì„œë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.

```python

import re
import requests
from urllib.parse import urlsplit
import os

# https ì‚¬ìš© ì‹œ ì¸ì¦ì„œ ë“±ë¡
os.environ["cert_for_kubeflow"] = "/Users/git_repo/Learning_kubeflow/manifests/deployment/cert/leeway.crt"



def get_istio_auth_session(url: str, username: str, password: str) -> dict:
    """
    Determine if the specified URL is secured by Dex and try to obtain a session cookie.
    WARNING: only Dex `staticPasswords` and `LDAP` authentication are currently supported
             (we default default to using `staticPasswords` if both are enabled)

    :param url: Kubeflow server URL, including protocol
    :param username: Dex `staticPasswords` or `LDAP` username
    :param password: Dex `staticPasswords` or `LDAP` password
    :return: auth session information
    """
    # define the default return object
    auth_session = {
        "endpoint_url": url,  # KF endpoint URL
        "redirect_url": None,  # KF redirect URL, if applicable
        "dex_login_url": None,  # Dex login URL (for POST of credentials)
        "is_secured": None,  # True if KF endpoint is secured
        "session_cookie": None,  # Resulting session cookies in the form "key1=value1; key2=value2"
    }

    # use a persistent session (for cookies)
    with requests.Session() as s:

        ################
        # Determine if Endpoint is Secured
        ################
        resp = s.get(url, allow_redirects=True, verify=os.getenv("cert_for_kubeflow"))
        if resp.status_code != 200:
            raise RuntimeError(f"HTTP status code '{resp.status_code}' for GET against: {url}")

        auth_session["redirect_url"] = resp.url

        # if we were NOT redirected, then the endpoint is UNSECURED
        if len(resp.history) == 0:
            auth_session["is_secured"] = False
            return auth_session
        else:
            auth_session["is_secured"] = True

        ################
        # Get Dex Login URL
        ################
        redirect_url_obj = urlsplit(auth_session["redirect_url"])

        # if we are at `/auth?=xxxx` path, we need to select an auth type
        if re.search(r"/auth$", redirect_url_obj.path):

            #######
            # TIP: choose the default auth type by including ONE of the following
            #######

            # OPTION 1: set "staticPasswords" as default auth type
            redirect_url_obj = redirect_url_obj._replace(
                path=re.sub(r"/auth$", "/auth/local", redirect_url_obj.path)
            )
            # OPTION 2: set "ldap" as default auth type
            # redirect_url_obj = redirect_url_obj._replace(
            #     path=re.sub(r"/auth$", "/auth/ldap", redirect_url_obj.path)
            # )

        # if we are at `/auth/xxxx/login` path, then no further action is needed (we can use it for login POST)
        if re.search(r"/auth/.*/login$", redirect_url_obj.path):
            auth_session["dex_login_url"] = redirect_url_obj.geturl()

        # else, we need to be redirected to the actual login page
        else:
            # this GET should redirect us to the `/auth/xxxx/login` path
            resp = s.get(redirect_url_obj.geturl(), allow_redirects=True)
            if resp.status_code != 200:
                raise RuntimeError(
                    f"HTTP status code '{resp.status_code}' for GET against: {redirect_url_obj.geturl()}"
                )

            # set the login url
            auth_session["dex_login_url"] = resp.url

        ################
        # Attempt Dex Login
        ################
        resp = s.post(
            auth_session["dex_login_url"],
            data={"login": username, "password": password},
            allow_redirects=True,
        )
        if len(resp.history) == 0:
            raise RuntimeError(
                f"Login credentials were probably invalid - "
                f"No redirect after POST to: {auth_session['dex_login_url']}"
            )

        # store the session cookies in a "key1=value1; key2=value2" string
        auth_session["session_cookie"] = "; ".join([f"{c.name}={c.value}" for c in s.cookies])
    return auth_session


import kfp
import os

KUBEFLOW_ENDPOINT = "https://localhost:8080"
KUBEFLOW_USERNAME = "user@example.com"
KUBEFLOW_PASSWORD = "12341234"


auth_session = get_istio_auth_session(
    url=KUBEFLOW_ENDPOINT, username=KUBEFLOW_USERNAME, password=KUBEFLOW_PASSWORD
)

client = kfp.Client(
    host=f"{KUBEFLOW_ENDPOINT}/pipeline",
    cookies=auth_session["session_cookie"],
    ssl_ca_cert=os.getenv("cert_for_kubeflow"),
)

if __name__ == "__main__":
    client.create_run_from_pipeline_func(
        NLP_Pipeline, arguments={}, namespace="kubeflow-user-example-com"
    )

```

<br/>

#### â– íŒŒì´í”„ë¼ì¸ ì •ìƒ ë°°í¬ ì—¬ë¶€ ì²´í¬

íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ì„ ì™„ë£Œí–ˆë‹¤ë©´ ëª¨ë¸ ì„œë¹™ì´ ì •ìƒì ìœ¼ë¡œ ì´ë¤„ì¡ŒëŠ”ì§€ ìš”ì²­(request)ì„ ë³´ë‚´ê² ìŠµë‹ˆë‹¤.

```python
torchserve_name = "torch-model"
model_name = "torchserve"
url = f"https://localhost:8080/v1/models/{torchserve_name}:predict"
host = f"{model_name}.kubeflow-user-example-com.example.com"
session={'authservice_session':auth_session["session_cookie"].replace('authservice_session=','')}
data = {"instances": [{"data": "Hello World!"}]}  # data

x = requests.post(
    url=url, verify=False, cookies=session, headers={"Host": host}, json=data
)
x.text
```

<br/>

> `torchserve_name`ì€ config.propertiesì˜ model_snapshotì—ì„œ í™•ì¸í•˜ê±°ë‚˜ ì•„ë˜ì™€ ê°™ì´ kserve_container ë¡œê·¸ì— ë“¤ì–´ê°€ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
>
> <img src='/assets/blog/mlops/kubeflow/pipeline_using_kfp/img7.png' alt='img7'>

<br/>
